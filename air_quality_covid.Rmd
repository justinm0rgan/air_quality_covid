---
title: "Air Quality COVID - Data Loading"
author: "Justin Williams"
date: "5/7/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load-packages}
library(tidyverse)
library(dotenv)
library(RSocrata)
library(RAQSAPI)
library(jsonlite)
library(rlist)
```


## Load data

Load data from API's.

```{r covid-api-call}
# load up hidden api key
load_dot_env()

# import datasets to R
covid_df <- read.socrata("https://data.cdc.gov/resource/kn79-hsxy.json",
             app_token = Sys.getenv("SOCRATA_API"))

# save df to data folder
write_csv(covid_df, paste("./data/us_covid_cases_and_deaths_county_",Sys.Date(),".csv", sep = ""))
```

Air quality API call

```{r aqs-api-call}
aqs_credentials(username = "justinmorganwilliams@gmail.com",
                key = Sys.getenv("AQS_API"))
```

Get state and county use NYC as proxy, will most likely do LA, Chicago and New York.

```{r get-fips-codes, warning=FALSE}
# get ny state fips
state_fips <- aqs_states()
ny_fips <- state_fips[state_fips$state == "New York",]$stateFIPS

# set county fips df
ny_county_fips <- aqs_counties_by_state(ny_fips)

# create list of county names in nyc
nyc_county_names = c("Bronx", "Kings", "New York", "Queens", "Richmond")

# get nyc county fips
nyc_county_fips <- as.list(ny_county_fips[ny_county_fips$county_name %in% nyc_county_names,]$county_code)


# get sites by county
# may need to make this a function

# set length of vector
nyc_county_sites <- vector("character", length(nyc_county_fips))

# loop through county_fips
for (i in seq_along(nyc_county_fips)) {
  nyc_county_sites[i] <- aqs_sites_by_county(
    stateFIPS = ny_fips,
    countycode = nyc_county_fips[[i]]
  )
}

nyc_county_sites
```

Get parameter codes for pollutants.

```{r parameter-codes}
parm_json <- fromJSON("https://aqs.epa.gov/data/api/list/parametersByClass?email=test@aqs.api&key=test&pc=CRITERIA", flatten = T)

parm_json$Data
```

Look at sample data per county.

```{r sample-data-county}
aqs_sampledata_by_county(
  parameter = "88101",
  bdate = as.Date("20200301",
                  format = "%Y%m%d"),
  edate = as.Date("20200331",
                  format = "%Y%m%d"),
  stateFIPS = ny_fips,
  countycode = nyc_county_fips[[1]]
)

# set up sample vector for iteration
nyc_county_pm2.5 <- vector("character", length(nyc_county_fips))

# need to write a function to iterate over this and 
# make it one big dataframe
# maybe use rbind in a function?

for (i in seq_along(nyc_county_fips)) {
  nyc_county_pm2.5 <- 
    aqs_sampledata_by_county(
      parameter = "88101",
      bdate = as.Date("20200301",
                  format = "%Y%m%d"),
      edate = as.Date("20200331",
                  format = "%Y%m%d"),
      stateFIPS = ny_fips,
      countycode = nyc_county_fips[[i]])
}

nyc_county_pm2.5

# try it with mapply
m_test <- mapply(aqs_sampledata_by_county,
       countycode = nyc_county_fips,
       MoreArgs = list(parameter = "88101",
       bdate = as.Date("20200301",
                  format = "%Y%m%d"),
       edate = as.Date("20200331",
                  format = "%Y%m%d"),
       stateFIPS = ny_fips),
       SIMPLIFY = F)

# ok the above makes a list with dataframes in it

# try this with map purr
# this works perfectly, flattening the list with map_dfr and list.flatten
nyc_county_sample_data <- map(.x = nyc_county_fips,
     aqs_sampledata_by_county,
     parameter = "88101",
       bdate = as.Date("20200301",
                  format = "%Y%m%d"),
       edate = as.Date("20200331",
                  format = "%Y%m%d"),
       stateFIPS = ny_fips) %>% 
  map_dfr(list.flatten)

nyc_county_sample_data
```


Ok, now that I have FIPS codes, let's load up some data. I will start by looking at 

## Overview

Some stuff to look at:
  - Maybe include a table of pollutants, parameter and description?
  - Aggregate all hourly to daily or 24 hour, don't want to go less then 24 hours
  - What is the difference in `method_code`? Is there a data dictionary somewhere?
  - Geospatial map of all stations?
  - Maybe look a year or two prior to COVID to view diff?
  - Should I work with date local or GMT?
  
Seasonality
  - Add year, month, day columns to df so can aggregate as such
  - Format date column as datetime
  - Line charts with plot function, can have multiple on chart. Maybe this would make sense with multiple chemicals in air quality? I wonder if I can import a dataframe with more then one parameter from the API, if so maybe sum them all together to get a total figure and have different variables to compare?
  - Box plots grouped by year, month, day of different pollutants? Seasonality, yearly, monthly, weekly?
  - summary, colSums for na?
  - can have multiple plots on one par(mfrm = c())

Frequency
  - Frequency select min by daily, monthly, yearly if anything missing need to forward fill or backward fill missing data. Fill function in tidyr
  - should i say that each station should have data for each day?
  
Trends
  - Rolling means smooth time series by averaging out variations at frequencies
  - What parameter to take a rolling mean of?
  - Use **zoo** package to get rolling mean, calculate how many days you want, first arrange desc by year, then group by year then mutate then ungroup which will create a rolling average
  - Can also do yearly, half-yearly, quartley etc...
  - add plot for then add rolling mean as point in base R, can add multiple rolling means can use lines too, add legend
  - 7 day smooths out weekly seasonality but maintains yearly seasonality
  - yearly rolling mean shows long term trend

COVID Specific
  - pivot longer so that date is in column
  - mutate with lubridate to mdy(), group_by county, date, summarise deaths or cases row
  the ungroup
  - this may cumulative total, to change that and look at new cases can use lag function.
  - to use lag function arrange by date, then group by county then mutate by subtracting cumsum - lag(cumsum, default = 0)
  - change scale_x_date, can facet wrap by county with scales = "free_y"
  - trends can effect stationarity, can lead to underestimating future observations.
  - a dataset is stationary once you remove the trend
  - use ma() moving average function to get trend, can plot on top of data with plot
  - subtract data from trend, left with seasonal and random (if additive model)
  
Decompose
  - ts() function?
  - decompose? plot(decompose(df))
    - breaks into seasonality, trend, observed, random (residuals)
    - additive (seasonal+trend+random) 
    - multiplicative (seasonsalxtrendxrandom) for exponential growth
    - pattern in random? indicative of a time series thats not additive
    - set decompose function to specific object
      - $seasonal, $trend (using moving average functionality), $random
  

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
